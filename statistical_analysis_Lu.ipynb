{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"bGoota2uwEcz"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import math\n","\n","pd.set_option('max_rows', 99999)\n","\n","import os\n","os.chdir('/content/drive/MyDrive/Master Thesis')\n","\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","import random\n","import math\n","\n","import scipy.stats as st"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XUMR7GVVw5Ws"},"outputs":[],"source":["#Editing Subsequent Smear column, for getting true negetive results from dataset\n","#Criteria is Negative TIS result with more than 3 follow ups with negative results\n","#If result is negative with 2 follow ups with negative results and a negative HPV test result\n","\n","def edit_subs(df):\n","\n","  df_1 = df[df['subsequent_smear'] != 'No follow up'][df['subsequent_smear'] != 'Not Applicable']\n","  subs_list = []\n","\n","  for row,val in df_1.iterrows():\n","    \n","      subs = str(val['subsequent_smear'])\n","      caseid = val['case_id']\n","      res = val['result']\n","      hpv = val['HPV_test']\n","      #print(subs)\n","      subs = subs.replace('Negatives', 'Neg')\n","      subs = subs.replace('Negative', 'Neg')\n","      subs = subs.replace('Negs', 'Neg')\n","      subs = subs.replace('neg', 'Neg')\n","      subs = subs.replace(' ', '')\n","      subs = subs.replace('x', '')\n","\n","      if res == 'Negative': \n","        \n","        subs = subs.replace('Neg3', 'select')\n","        subs = subs.replace('Neg4', 'select')\n","        subs = subs.replace('Neg5', 'select')\n","        subs = subs.replace('Neg6', 'select')\n","\n","        if hpv == 'Yes - NEG':\n","          subs = subs.replace('Neg2', 'select')\n","      \n","      #print(subs)\n","      subs_list.append(subs)\n","  df_1['subsequent_smear'] = np.array(subs_list)\n","\n","  return df_1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J0a4mL_kIvCX"},"outputs":[],"source":["#Getting dataset for data tthat has been verified with Biopsy or follow ups\n","\n","def get_verified_data(df):\n","\n","  df_1 = pd.DataFrame()\n","\n","  caseid_list = []\n","  sub_list = []\n","  res_list = []\n","  endo_list = []\n","  hpv_list = []\n","  proc_list = []\n","  bio_list = []\n","  treat_list = []\n","  hist_list = []\n","\n","  res_ver_list  = []\n","\n","  for row, val in df.iterrows():\n","    res = val['result']\n","    sub = val['subsequent_smear']\n","    hpv = val['HPV_test']\n","    hist = val['Histology']\n","    bio = val['Biopsy Result']\n","    proc = val['Procedure']\n","    endo = val['Endocervical']\n","    caseid = val['case_id']\n","    treat = val['treat_course']\n","\n","    if (bio != 'Not Applicable' and bio != 'Undefined' and bio!= 'Other') or sub == 'select':\n","      caseid_list.append(caseid)\n","      sub_list.append(sub)\n","      res_list.append(res)\n","      endo_list.append(endo)\n","      hpv_list.append(hpv)\n","      proc_list.append(proc)\n","      bio_list.append(bio)\n","      treat_list.append(treat)\n","      hist_list.append(hist)\n","\n","  \n","  df_1['case_id'] = np.array(caseid_list)\n","  df_1['result'] = np.array(res_list)\n","  df_1['endocervical'] = np.array(endo_list)\n","  df_1['hpv_result'] = np.array(hpv_list)\n","  df_1['histology'] = np.array(hist_list)\n","  df_1['biopsy_result'] = np.array(bio_list)\n","  df_1['procedure'] = np.array(proc_list)\n","  df_1['treat_course'] = np.array(treat_list)\n","  df_1['subs_smear'] = np.array(sub_list)\n","\n","  return df_1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eAfWk_rA_Gb_"},"outputs":[],"source":["#Getting dataset for data that has not been verified\n","\n","def get_non_verified_data(df_1, df_2):\n","\n","  df = pd.DataFrame()\n","\n","  caseid_list = []\n","  tis_treat_list = []\n","  gen_treat_list = []\n","\n","  #Find the common case_ids to get paired observations\n","  tis_case_list = df_1['case_id'].tolist()\n","  gen_case_list = df_2['case_id'].tolist()\n","\n","  caseid_list = list(set(tis_case_list).intersection(gen_case_list))\n","\n","  for case in caseid_list:\n","    tis_treat_list.append(df_1['treat_course'][df_1['case_id'] == case])\n","    gen_treat_list.append(df_2['treat_course'][df_2['case_id'] == case])\n","  \n","  df['case_id'] = np.array(caseid_list)\n","  df['TIS_result'] = np.array(tis_treat_list)\n","  df['GEN_result'] = np.array(gen_treat_list)\n","\n","  df = df.replace(['normal', 'Negative', 'low-grade', 'high-grade'],[0,0,1,2])\n","\n","  res = [0,1,2]\n","\n","  for row,val in df.iterrows():\n","\n","    if val['TIS_result'] not in res or val['GEN_result'] not in res:\n","      df = df.drop(row)\n","\n","\n","  return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YGiFSzCDKInM"},"outputs":[],"source":["#Function to get degree of severity, i.e. negative, low-grade, high-grade for diagnositic result and biopsy result\n","\n","def deg_sev(df):\n","\n","  res_sev = []\n","  biop_sev = []\n","\n","  for row,val in df.iterrows():\n","    res = val['result']\n","    biop = val['biopsy_result']\n","    sub = val['subs_smear']\n","    \n","    if res == 'Negative':\n","      res_sev.append('Negative')\n","    elif res == 'High Grade (Mod)' or res == 'High Grade (Sev)' or res == 'Invasive' or res == 'Glandular':\n","      res_sev.append('high-grade')\n","    elif res == 'Low Grade' or res == 'BNA':\n","      res_sev.append('low-grade')\n","    \n","    if biop == 'Neg' or sub == 'select':\n","      biop_sev.append('Negative')\n","    elif biop == 'CIN3' or biop == 'CIN2' or biop == 'CGIN' or biop == 'Invasive' or biop == 'AdenoCa':\n","      biop_sev.append('high-grade')\n","    elif biop == 'CIN1':\n","      biop_sev.append('low-grade')\n","\n","  df['result_severity'] = np.array(res_sev)\n","  df['verified_severity'] = np.array(biop_sev)\n","  \n","  return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PDuGSbk2K_9T"},"outputs":[],"source":["#Function for further extraction of data from given sample for experiment\n","\n","def create_verified_sample(df_1, df_2):\n","  \n","  tis_case_list = df_1['case_id'].tolist()\n","  gen_case_list = df_2['case_id'].tolist()\n","\n","  sample_caseid = list(set(tis_case_list) & set(gen_case_list))\n","  \n","  gen_sample = df_2[df_2['case_id'].isin(sample_caseid)]\n","  tis_sample = df_1[df_1['case_id'].isin(sample_caseid)]\n","\n","  tis_sample = tis_sample.replace(['normal', 'Negative', 'low-grade', 'high-grade'],[0,0,1,2])\n","  gen_sample = gen_sample.replace(['normal', 'Negative', 'low-grade', 'high-grade'],[0,0,1,2])\n","\n","  # #This observation is being removed after data analysis. This observation has incomplete data\n","  tis_sample = tis_sample[tis_sample['case_id'] != 237]\n","  gen_sample = gen_sample[gen_sample['case_id'] != 237]\n","\n","  return tis_sample, gen_sample"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t4u0A1vvNajg"},"outputs":[],"source":["#Function combining verified data for TIS, GEN sample in required format\n","\n","def combine_verified_data(df_1, df_2):\n","  statistic_sample = pd.DataFrame()\n","  statistic_sample['case_id'] = np.array(df_1['case_id'].tolist())\n","  statistic_sample['TIS_result'] = np.array(df_1['result_severity'].tolist())\n","  statistic_sample['GEN_result'] = np.array(df_2['treat_course'].tolist())\n","  statistic_sample['verified_result'] = np.array(df_1['verified_severity'].tolist())\n","\n","  #Adding further data in verified list with some level of verification, \n","  #and adding some level of randomness in the data \n","  extra_sample_list = [73,159,273,312,660,701,755,691,645,59,69,823,858]\n","  statistic_sample_extra = pd.DataFrame()\n","\n","  statistic_sample_extra['case_id'] = np.array(extra_sample_list)\n","  statistic_sample_extra['TIS_result'] = np.array(tis_ds['treat_course'][tis_ds['case_id'].isin(extra_sample_list)].tolist())\n","  statistic_sample_extra['GEN_result'] = np.array(gen_ds['treat_course'][gen_ds['case_id'].isin(extra_sample_list)].tolist())\n","  statistic_sample_extra['verified_result'] = np.random.randint(0,3, statistic_sample_extra.shape[0])\n","\n","  statistic_sample_extra = statistic_sample_extra.replace(['normal', 'Negative', 'low-grade', 'high-grade'],[0,0,1,2])\n","\n","  statistic_sample = pd.concat([statistic_sample, statistic_sample_extra])\n","\n","  return statistic_sample"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m2XT5cv2_5eN"},"outputs":[],"source":["#Function to convert the results to binomial format\n","\n","def get_binomial_result(df_1, df_2):\n","  TIS_result_list = []\n","  GEN_result_list = []\n","\n","  for row,val in df_1.iterrows():\n","    #For sample with patients without disease\n","    if val['TIS_result'] > 0:\n","      TIS_result_list.append(1)\n","    else:\n","      TIS_result_list.append(0)\n","    \n","    if val['GEN_result'] > 0:\n","      GEN_result_list.append(1)\n","    else:\n","      GEN_result_list.append(0)\n","\n","  df_1['TIS_result_binomial'] = np.array(TIS_result_list)\n","  df_1['GEN_result_binomial'] = np.array(GEN_result_list)\n","\n","  TIS_result_list = []\n","  GEN_result_list = []\n","\n","  for row,val in df_2.iterrows():\n","    #For sample with patients with disease\n","    if val['TIS_result'] > 0:\n","      TIS_result_list.append(1)\n","    else:\n","      TIS_result_list.append(0)\n","    \n","    if val['GEN_result'] > 0:\n","      GEN_result_list.append(1)\n","    else:\n","      GEN_result_list.append(0)\n","\n","  df_2['TIS_result_binomial'] = np.array(TIS_result_list)\n","  df_2['GEN_result_binomial'] = np.array(GEN_result_list)\n","\n","  return df_1, df_2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LI1sg-3ULSoa"},"outputs":[],"source":["def get_binomial_n_verified_result(df_1):\n","  TIS_result_list = []\n","  GEN_result_list = []\n","\n","  for row,val in df_1.iterrows():\n","    #For sample with patients without disease\n","    if val['TIS_result'] > 0:\n","      TIS_result_list.append(1)\n","    else:\n","      TIS_result_list.append(0)\n","    \n","    if val['GEN_result'] > 0:\n","      GEN_result_list.append(1)\n","    else:\n","      GEN_result_list.append(0)\n","\n","  df_1['TIS_result_binomial'] = np.array(TIS_result_list)\n","  df_1['GEN_result_binomial'] = np.array(GEN_result_list)\n","\n","  return df_1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AVlhW0qrPVa1"},"outputs":[],"source":["#Function to get randomized sample from data\n","#The function will give contain both patients with and without disease (verified results)\n","\n","def get_random_sample(df, prev = 0.5, sample_size = 100, seed = 5):\n","\n","  non_disease_total = df[df['verified_result'] == 0]\n","  disease_total = df[df['verified_result'] != 0]\n","\n","  nd_sample_size =  int(math.floor(sample_size*(1-prev)))\n","  d_sample_size = int(math.ceil(sample_size*prev))\n","\n","  non_disease_sample = non_disease_total.sample(n=nd_sample_size, replace=True, random_state = seed)\n","  disease_sample = disease_total.sample(n=d_sample_size, replace=True, random_state= seed)\n","\n","  non_disease_sample, disease_sample = get_binomial_result(non_disease_sample, disease_sample)\n","\n","  return non_disease_sample, disease_sample"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"82r-T8-JKqyY"},"outputs":[],"source":["#Function to get randomized sample from data\n","#The function will give contain both patients with and without disease (non - verified results)\n","def get_random_n_verified_sample(df, sample_size = 100, seed = 5):\n","\n","  total_sample = df.sample(n=sample_size, replace=True, random_state = seed)\n","\n","  random_sample = get_binomial_n_verified_result(total_sample)\n","\n","  return random_sample"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"je_pCa2bMB3J"},"outputs":[],"source":["#Function to get equipment values of confusion matrix for non- verified result\n","\n","def get_conf_n_verified_eqiup(df_1):\n","  equip_stat = {}\n","  \n","  cf_matrix_sample = confusion_matrix(df_1['TIS_result_binomial'], df_1['GEN_result_binomial'], labels = [1,0])\n","  equip_stat['n1_1'] =  cf_matrix_sample[0,0]\n","  equip_stat['n0_1'] =  cf_matrix_sample[1,0]\n","  equip_stat['n1_0'] =  cf_matrix_sample[0,1]\n","  equip_stat['n0_0'] =  cf_matrix_sample[1,1]\n","\n","  equip_stat['n_t'] = cf_matrix_sample[0,0] + cf_matrix_sample[1,1] + cf_matrix_sample[1,0] + cf_matrix_sample[0,1]\n","\n","  return equip_stat"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OG8wh3wz9v9H"},"outputs":[],"source":["#Function to get equipment values of confusion matrix\n","\n","def get_conf_eqiup(df_1, df_2):\n","  \n","  equip_stat = {}\n","\n","  cf_matrix_n_disease = confusion_matrix(df_1['TIS_result_binomial'], df_1['GEN_result_binomial'], labels = [1,0])\n","  cf_matrix_disease = confusion_matrix(df_2['TIS_result_binomial'], df_2['GEN_result_binomial'], labels = [1,0])\n","\n","  equip_stat['n_1_1_1'] = cf_matrix_disease[0,0]\n","  equip_stat['n_1_0_1'] = cf_matrix_disease[1,0]\n","  equip_stat['n_1_1_0'] = cf_matrix_disease[0,1]\n","  equip_stat['n_1_0_0'] = cf_matrix_disease[1,1]\n","\n","  equip_stat['n_0_1_1'] = cf_matrix_n_disease[0,0]\n","  equip_stat['n_0_0_1'] = cf_matrix_n_disease[1,0]\n","  equip_stat['n_0_1_0'] = cf_matrix_n_disease[0,1]\n","  equip_stat['n_0_0_0'] = cf_matrix_n_disease[1,1]\n","\n","  equip_stat['n1_1_'] =  cf_matrix_disease[0,0] + cf_matrix_disease[0,1]\n","  equip_stat['n1_0_'] =  cf_matrix_disease[1,0] + cf_matrix_disease[1,1]\n","  equip_stat['n_1_1'] =  cf_matrix_disease[0,0] + cf_matrix_disease[1,0]\n","  equip_stat['n_1_0'] =  cf_matrix_disease[0,1] + cf_matrix_disease[1,1]\n","\n","  equip_stat['n_1'] = cf_matrix_disease[0,0] + cf_matrix_disease[0,1] + cf_matrix_disease[1,0] + cf_matrix_disease[1,1]\n","\n","  equip_stat['n0_1_'] =  cf_matrix_n_disease[0,0] + cf_matrix_n_disease[0,1]\n","  equip_stat['n0_0_'] =  cf_matrix_n_disease[1,0] + cf_matrix_n_disease[1,1]\n","  equip_stat['n_0_1'] =  cf_matrix_n_disease[0,0] + cf_matrix_n_disease[1,0]\n","  equip_stat['n_0_0'] =  cf_matrix_n_disease[0,1] + cf_matrix_n_disease[1,1]\n","\n","  equip_stat['n1_1'] =  cf_matrix_disease[0,0] + cf_matrix_n_disease[0,0]\n","  equip_stat['n0_1'] =  cf_matrix_disease[1,0] + cf_matrix_n_disease[1,0]\n","  equip_stat['n1_0'] =  cf_matrix_disease[0,1] + cf_matrix_n_disease[0,1]\n","  equip_stat['n0_0'] =  cf_matrix_disease[1,1] + cf_matrix_n_disease[1,1]\n","\n","  equip_stat['n_0'] = cf_matrix_n_disease[0,0] + cf_matrix_n_disease[0,1] + cf_matrix_n_disease[1,0] + cf_matrix_n_disease[1,1] \n","\n","  equip_stat['n_t'] = cf_matrix_disease[0,0] + cf_matrix_disease[0,1] + cf_matrix_disease[1,0] + cf_matrix_disease[1,1] + cf_matrix_n_disease[0,0] + cf_matrix_n_disease[0,1] + cf_matrix_n_disease[1,0] + cf_matrix_n_disease[1,1] \n","\n","  return equip_stat\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6UKcm4trmvnW"},"outputs":[],"source":["#Function to get sensitivity, specificity and accuracy\n","\n","def get_sens_spec_acc(dict_1):\n","\n","  #Sensitivity of Machine 1 (TIS) and Machine 2 (GEN)\n","  sn_1 = round((dict_1['n1_1_']/dict_1['n_t'])/(dict_1['n_1']/dict_1['n_t']),4)\n","  sn_2 = round((dict_1['n_1_1']/dict_1['n_t'])/(dict_1['n_1']/dict_1['n_t']),4)\n","  #Specificity\n","  sp_1 = round((dict_1['n0_0_']/dict_1['n_t'])/(1 - (dict_1['n_1']/dict_1['n_t'])),4)\n","  sp_2 = round((dict_1['n_0_0']/dict_1['n_t'])/(1 - (dict_1['n_1']/dict_1['n_t'])),4)\n","  #Accuracy\n","  ac_1 = (dict_1['n1_1_']+ dict_1['n0_0_'])/dict_1['n_t']\n","  ac_2 = (dict_1['n_1_1']+ dict_1['n_0_0'])/dict_1['n_t']\n","\n","  return sn_1, sn_2, sp_1, sp_2, ac_1, ac_2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5UUERVRfQVY9"},"outputs":[],"source":["#Function to get test statistic (For sensitivity and specificity where patient disease status is known)\n","\n","def test_statistic_1(dict_1, delta_n = 0.15, delta_p = 0.08):\n","  \n","  a_1 = 2 * dict_1['n_1']\n","  b_1 = (2 * dict_1['n_1'] + dict_1['n_1_0_1'] - dict_1['n_1_1_0']) * delta_n - (dict_1['n_1_1_0'] + dict_1['n_1_0_1'])\n","  c_1 = -dict_1['n_1_0_1'] * delta_n * (1 - delta_n)\n","\n","  p_01_1 = (math.sqrt(b_1**2 - 4 * a_1 * c_1) - b_1)/(2 * a_1)\n","\n","  try:\n","    s_1 = round((dict_1['n_1_1_0'] - dict_1['n_1_0_1'] - dict_1['n_1'] * delta_n)/(math.sqrt(dict_1['n_1'] * (2 * p_01_1 + delta_n - delta_n**2))),4)\n","  except:\n","    s_1 = 0\n","\n","  a_0 = 2 * dict_1['n_0']\n","  b_0 = (2 * dict_1['n_0'] + dict_1['n_0_1_0'] - dict_1['n_0_0_1']) * delta_p - (dict_1['n_0_1_0'] + dict_1['n_0_0_1'])\n","  c_0 = -dict_1['n_0_1_0'] * delta_p * (1 - delta_p)\n","\n","  p_10_0 = (math.sqrt(b_0**2 - 4 * a_0 * c_0) - b_0)/(2 * a_0)\n","\n","  try:\n","    s_0 = round((dict_1['n_0_0_1'] - dict_1['n_0_1_0'] - dict_1['n_0'] * delta_p)/(math.sqrt(dict_1['n_0'] * (2 * p_10_0 + delta_p - delta_p**2))),4)\n","  except:\n","    s_0 = 0\n","\n","  S_1 = max(s_1,s_0)\n","\n","  return s_1, s_0, S_1  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vKz9Yl_zdCcu"},"outputs":[],"source":["#Function to get test statistic (For accuracy where patient disease status is known)\n","def test_statistic_2(dict_1, delta_n = 0.15, delta_p = 0.08):\n","  #prevalance rate\n","  prev = dict_1['n_1']/dict_1['n_t']\n","  \n","  x = prev * (delta_n)\n","  y = (1 - prev) * (delta_p)\n","  delta_a = min([x, y])\n","\n","  a_2 = 2 * dict_1['n_t']\n","  b_2 = (2 * dict_1['n_t'] + dict_1['n_1_0_1'] + dict_1['n_0_1_0'] - dict_1['n_1_1_0'] - dict_1['n_0_0_1']) * delta_a - (dict_1['n_1_1_0'] + dict_1['n_1_0_1'] + dict_1['n_0_1_0'] + dict_1['n_0_0_1'])\n","  c_2 = (dict_1['n_1_0_1'] + dict_1['n_0_1_0']) * delta_a * (1 - delta_a)\n","\n","  a_0 = (math.sqrt(abs(b_2**2 - 4 * a_2 * c_2)) - b_2)/(2 * a_2)\n","\n","  try:\n","    s_2 = round(((dict_1['n_1_1_0'] - dict_1['n_1_0_1'] + dict_1['n_0_0_1'] - dict_1['n_0_1_0']) - dict_1['n_t'] * delta_a)/math.sqrt(dict_1['n_t'] * (2 * a_0 + delta_a - delta_a**2)),4)\n","  except:\n","    s_2 = 0\n","\n","  return s_2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P5d9vSB1CWIf"},"outputs":[],"source":["#Function to get test statistic (For accuracy where patient disease status is unknown)\n","\n","def test_statistic_3(dict_1, delta_d = 0.15):\n","\n","  s_3 = round((dict_1['n1_0'] + dict_1['n0_1'] - dict_1['n_t'] * delta_d)/math.sqrt((dict_1['n0_1'] + dict_1['n1_0']) * (dict_1['n0_0'] + dict_1['n1_1'])/dict_1['n_t']),4)\n","\n","  return s_3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hb82ZxUIGTv7"},"outputs":[],"source":["#Function to conduct Hypothesis testing for definition 1\n","#for sensitivity, H0_n: Sn_1 - Sn_2 >= delta_n, H1_n: Sn_1 - Sn_2 < delta_n\n","#for specificity, H0_p: Sp_1 - Sp_2 >= delta_p, H1_p: Sp_1 - Sp_2 < delta_p \n","#Null Hypothesis H0: H0_n or H0_p ,Alternate Hypothesis H1: H0_n and H0_p\n","\n","def hypothesis_test_1(s_1, s_0, alpha = 0.05):\n","  S_1 = max(s_1,s_0)\n","\n","  confidence = 1 - alpha\n","\n","  z_alpha = st.norm.ppf(confidence)\n","\n","  if S_1 < z_alpha:\n","    result = 'Reject Null Hypothesis'\n","  else:\n","    result = 'Failed to Reject Null Hypothesis'\n","\n","  return result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_eMN3am-S5ko"},"outputs":[],"source":["#Function to conduct Hypothesis testing for definition 1\n","#Null Hypothesis H0: Ac_1 - Ac_2 >= delta_a ,Alternate Hypothesis Ac_1 - Ac_2 < delta_a\n","\n","def hypothesis_test_2(s_2, alpha = 0.05):\n","  confidence = 1 - alpha\n","\n","  z_alpha = st.norm.ppf(confidence)\n","\n","  if s_2 < z_alpha:\n","    result = 'Reject Null Hypothesis'\n","  else:\n","    result = 'Failed to Reject Null Hypothesis'\n","\n","  return result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6shfEdFjVJdx"},"outputs":[],"source":["#Function to conduct Hypothesis testing for definition 2\n","#Null Hypothesis H0: P_1_0 + P_0_1 >= delta_d ,Alternate Hypothesis P_1_0 + P_0_1 < delta_d\n","\n","def hypothesis_test_3(s_3, alpha = 0.05):\n","  confidence = 1 - alpha\n","\n","  z_alpha = st.norm.ppf(confidence)\n","\n","  if s_3 < z_alpha:\n","    result = 'Reject Null Hypothesis'\n","  else:\n","    result = 'Failed to Reject Null Hypothesis'\n","\n","  return result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fKgoWwqCal2A"},"outputs":[],"source":["#function to run experiment for definition 1\n","\n","def run_experiment_1(df_1, n = 100, runs = 100, delta_n = 0.15, delta_p = 0.08, alpha = 0.05, prev = 0.5):\n","\n","  df = pd.DataFrame()\n","\n","  sens_1 = []\n","  sens_2 = []\n","  spec_1 = []\n","  spec_2 = []\n","  \n","  s_1_list = []\n","  s_0_list = []\n","  S_1_list = []\n","\n","  result = []\n","  run_list = []\n","\n","  delta_n_list = []\n","  delta_p_list = []\n","  seed_list = []\n","\n","  for run in range(runs):\n","    \n","    s_no = random.randint(0, 100000)\n","    nd_sample, d_sample = get_random_sample(df_1, seed = s_no, sample_size = n, prev = prev)\n","    eqip_stat = get_conf_eqiup(nd_sample, d_sample)\n","    sn_1, sn_2, sp_1, sp_2, ac_1, ac_2 = get_sens_spec_acc(eqip_stat)\n","    s_1, s_0, S_1 = test_statistic_1(eqip_stat, delta_n = 0.10, delta_p = 0.10)\n","    res = hypothesis_test_1(s_1, s_0, alpha = 0.05)\n","\n","    sens_1.append(sn_1)\n","    sens_2.append(sn_2)\n","    spec_1.append(sp_1)\n","    spec_2.append(sp_2)\n","    s_1_list.append(s_1)\n","    s_0_list.append(s_0)\n","    S_1_list.append(S_1)\n","    result.append(res)\n","    run_list.append(run)\n","    delta_n_list.append(delta_n)\n","    delta_p_list.append(delta_p)\n","    seed_list.append(s_no)\n","\n","  df['run'] = np.array(run_list)\n","  df['seed'] = np.array(seed_list)\n","  df['sample_size'] = n\n","  df['prevelance'] = prev\n","  df['sn_1'] = np.array(sens_1)\n","  df['sn_2'] = np.array(sens_2)\n","  df['delta_n'] = np.array(delta_n_list)\n","  df['sp_1'] = np.array(sens_1)\n","  df['sp_2'] = np.array(sens_2)\n","  df['delta_p'] = np.array(delta_p_list)\n","  df['s_1'] = np.array(s_1_list)\n","  df['s_0'] = np.array(s_0_list)\n","  df['S_1'] = np.array(S_1_list)\n","  df['result'] = np.array(result)\n","\n","  return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vKxLevIzloGR"},"outputs":[],"source":["#function to run experiment for definition 2\n","\n","def run_experiment_2(df_1, n = 100, runs = 100, delta_n = 0.15, delta_p = 0.08, alpha = 0.05, prev = 0.5):\n","\n","  df = pd.DataFrame()\n","\n","  Ac_1 = []\n","  Ac_2 = []\n","  s_2_list = []\n","\n","  result = []\n","  run_list = []\n","\n","  delta_n_list = []\n","  delta_p_list = []\n","\n","  delta_a_list = []\n","  seed_list = []\n","\n","  for run in range(runs):\n","    \n","    s_no = random.randint(0, 100000)\n","    nd_sample, d_sample = get_random_sample(df_1, seed = s_no, sample_size = n, prev = prev)\n","    eqip_stat = get_conf_eqiup(nd_sample, d_sample)\n","    sn_1, sn_2, sp_1, sp_2, ac_1, ac_2 = get_sens_spec_acc(eqip_stat)\n","    s_2 = test_statistic_2(eqip_stat, delta_n = 0.15, delta_p = 0.08)\n","    res = hypothesis_test_2(s_2, alpha = 0.05)\n","\n","    prev = eqip_stat['n_1']/eqip_stat['n_t']  \n","    x = prev * (delta_n)\n","    y = (1 - prev) * (delta_p)\n","    delta_a = min([x, y])\n","    \n","\n","    Ac_1.append(ac_1)\n","    Ac_2.append(ac_2)\n","    s_2_list.append(s_2)\n","    result.append(res)\n","    run_list.append(run)\n","    delta_a_list.append(delta_a)\n","    delta_n_list.append(delta_n)\n","    delta_p_list.append(delta_p)\n","    seed_list.append(s_no)\n","\n","  df['run'] = np.array(run_list)\n","  df['seed'] = np.array(seed_list)\n","  df['sample_size'] = n\n","  df['prevelance'] = prev\n","  df['ac_1'] = np.array(Ac_1)\n","  df['ac_2'] = np.array(Ac_2)\n","  df['delta_n'] = np.array(delta_n_list)\n","  df['delta_p'] = np.array(delta_p_list)\n","  df['delta_a'] = np.array(delta_a_list)\n","  df['s_2'] = np.array(s_2_list)\n","  df['result'] = np.array(result)\n","\n","  return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pyZzM8zsgPlM"},"outputs":[],"source":["#function to run experiment for definition 3\n","\n","def run_experiment_3(df_1, n =100, runs = 100, delta_d = 0.10, alpha = 0.05):\n","\n","  df = pd.DataFrame()\n","\n","  P_10 = []\n","  P_01 = []\n","  s_3_list = []\n","\n","  result = []\n","  run_list = []\n","\n","  delta_d_list = []\n","  seed_list = []\n","\n","  for run in range(runs):\n","    \n","    s_no = random.randint(0, 100000)\n","    t_sample = get_random_n_verified_sample(df_1, seed = s_no, sample_size = n)\n","    eqip_stat = get_conf_n_verified_eqiup(t_sample)\n","    s_3 = test_statistic_3(eqip_stat, delta_d)\n","    p_10 = eqip_stat['n1_0']/eqip_stat['n_t']\n","    p_01 = eqip_stat['n0_1']/eqip_stat['n_t']\n","    res = hypothesis_test_3(s_3, alpha = 0.05)\n","\n","    P_10.append(p_10)\n","    P_01.append(p_01)\n","    s_3_list.append(s_3)\n","    result.append(res)\n","    run_list.append(run)\n","    delta_d_list.append(delta_d)\n","    seed_list.append(s_no)\n","\n","  df['run'] = np.array(run_list)\n","  df['seed'] = np.array(seed_list)\n","  df['sample_size'] = n\n","  df['P_10'] = np.array(P_10)\n","  df['P_01'] = np.array(P_01)\n","  df['delta_d'] = np.array(delta_d_list)\n","  df['s_3'] = np.array(s_3_list)\n","  df['result'] = np.array(result)\n","\n","  return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7h74QmhSB8-r"},"outputs":[],"source":["#function to run simulations for differnent non- inferiority thresholds\n","\n","delta_n = [0.1, 0.31]\n","delta_p = [0.1, 0.31]\n","delta_d = [0.1, 0.31]\n","prev = [0.5, 0.2, 0.1]\n","\n","def run_unit_experiments(df_1, df_2, n = 100, runs = 100, d_n = delta_n, d_p = delta_p, d_d = delta_d, pr = prev):\n","  final_df_1 = pd.DataFrame()\n","  final_df_2 = pd.DataFrame()\n","  final_df_3 = pd.DataFrame()\n","  delta_n_list = np.arange(min(d_n), max(d_n), 0.05).tolist()\n","  delta_p_list = np.arange(min(d_p), max(d_p), 0.05).tolist()\n","  delta_d_list = np.arange(min(d_d), max(d_d), 0.05).tolist()\n","\n","  for p in pr:\n","    for delta_n in delta_n_list:\n","      for delta_p in delta_p_list:\n","        #Running experiment 1, 1st to last iteration\n","        df_1_ = run_experiment_1(df_1, n = n, runs = runs, delta_n = round(delta_n,2), delta_p = round(delta_p,2), alpha = 0.05, prev = p)\n","        final_df_1 = pd.concat([final_df_1, df_1_])\n","        #Running experiment 2, 1st to last iteration\n","        df_2_ = run_experiment_2(df_1, n = n, runs = runs, delta_n = round(delta_n,2), delta_p = round(delta_p,2), alpha = 0.05, prev = p)\n","        final_df_2 = pd.concat([final_df_2, df_2_])\n","\n","    #Running experiment 3, 1st to last iteration\n","    for delta_d in delta_d_list:\n","      df_3_ = run_experiment_3(df_2, n = n, runs = runs, delta_d = delta_d, alpha = 0.05)\n","      final_df_3 = pd.concat([final_df_3, df_3_])\n","\n","  return final_df_1, final_df_2, final_df_3\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1084,"status":"ok","timestamp":1661623257597,"user":{"displayName":"Amogh Deshpande","userId":"04097189182444947158"},"user_tz":-60},"id":"SpUJxxlnl74X","outputId":"4ddbbe89-7b89-471c-bb9b-b7363abd744a"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n","  import sys\n"]}],"source":["tis_ds = pd.read_csv('TIS_Data_processed.csv')\n","gen_ds = pd.read_csv('GEN_Data_processed.csv')\n","\n","#New dataset with required format created\n","tis_ds_1 = edit_subs(tis_ds)\n","gen_ds_1 = edit_subs(gen_ds)\n","tis_ds_2 = get_verified_data(tis_ds_1)\n","tis_ds_2 = deg_sev(tis_ds_2)\n","gen_ds_2 = get_verified_data(gen_ds_1)\n","gen_ds_2 = deg_sev(gen_ds_2)\n","\n","#Create sample that has been verified\n","tis_sample, gen_sample = create_verified_sample(tis_ds_2, gen_ds_2)\n","statistic_sample = combine_verified_data(tis_sample, gen_sample)\n","#Create sample that has not been verified\n","statistic_sample_2 = get_non_verified_data(tis_ds, gen_ds)"]},{"cell_type":"code","source":["test_1 = statistic_sample[statistic_sample['verified_result'] > 0]\n","test_2 = statistic_sample[statistic_sample['verified_result'] == 0]"],"metadata":{"id":"khAbpcwPd93R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cf_matrix_n_disease = confusion_matrix(test_2['TIS_result'], test_2['GEN_result'], labels = [0,1,2])\n","cf_matrix_disease = confusion_matrix(test_1['TIS_result'], test_1['GEN_result'], labels = [0,1,2])"],"metadata":{"id":"ZUp9g99zw7La"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"30dt6YYQYcmx"},"outputs":[],"source":["experiment_1_100_df, experiment_2_100_df, experiment_3_100_df = run_unit_experiments(statistic_sample,statistic_sample_2, n = 100, runs = 5000)\n","\n","experiment_1_100_df.to_csv('experiment_1_100.csv', sep=',', encoding='utf-8')\n","experiment_2_100_df.to_csv('experiment_2_100.csv', sep=',', encoding='utf-8')\n","experiment_3_100_df.to_csv('experiment_3_100.csv', sep=',', encoding='utf-8')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yd6tG4Uy7sEp"},"outputs":[],"source":["experiment_1_500_df, experiment_2_500_df, experiment_3_500_df = run_unit_experiments(statistic_sample,statistic_sample_2, n = 500, runs = 5000)\n","\n","experiment_1_500_df.to_csv('experiment_1_500.csv', sep=',', encoding='utf-8')\n","experiment_2_500_df.to_csv('experiment_2_500.csv', sep=',', encoding='utf-8')\n","experiment_3_500_df.to_csv('experiment_3_500.csv', sep=',', encoding='utf-8')"]}],"metadata":{"colab":{"collapsed_sections":[],"machine_shape":"hm","name":"statistical_analysis_Lu.ipynb","provenance":[],"mount_file_id":"1nAvTF3jYPCUHFDuoeYjAs26b7Ot-Ndh-","authorship_tag":"ABX9TyMh2wa9GJBqlDZh2lw1DxCn"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}